{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95d29477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, optimizers\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33c19d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonso\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\PIL\\Image.py:970: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.67 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "AIimages = []\n",
    "new_size = (500, 500)\n",
    "AI_path = \"D:\\AI vs Real Classification\\AiArtData\\AiArtData\"\n",
    "\n",
    "for file in os.listdir(AI_path):\n",
    "    if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
    "        img = Image.open(os.path.join(AI_path, file)).convert('L').resize(new_size)\n",
    "        npArray = np.array(img)\n",
    "        AIimages.append(npArray)\n",
    "        \n",
    "RealImages = []\n",
    "Real_path = \"D:\\AI vs Real Classification\\RealArt\\RealArt\"\n",
    "\n",
    "for file in os.listdir(Real_path):\n",
    "    if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
    "        img = Image.open(os.path.join(Real_path, file)).convert('L').resize(new_size)\n",
    "        npArray = np.array(img)\n",
    "        RealImages.append(npArray)\n",
    "        \n",
    "AILabel = []\n",
    "RealLabel = []\n",
    "for _ in range(len(AIimages)): AILabel.append(0)\n",
    "for _ in range(len(RealImages)): RealLabel.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed4b94a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(913, 500, 500)\n",
      "(913,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(AIimages + RealImages)\n",
    "y_train = np.array(AILabel + RealLabel)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "49cd77b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "unison_shuffled_copies(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a62c6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained=None):\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(500, 500, 3)),\n",
    "        layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "        layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "        layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "        layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        layers.Flatten(), layers.Dropout(0.5),\n",
    "        layers.Dense(2, activation='softmax'),\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "build_model()\n",
    "\n",
    "def train(model = build_model(), sp = 'model.h5', epochs=10):\n",
    "    batch_size = 100\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_split = 0.1)\n",
    "    model.evaluate(x_test, y2_test, verbose=1)\n",
    "    model.save(sp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
